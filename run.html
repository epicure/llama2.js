<!DOCTYPE html>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- https://github.com/karpathy/llama2.c#notable-forks -->
<title>llama2.js</title>
<style>
    body {
        padding: 1em;
    }
    label, button {
        margin: 0.5em;
    }
    input {
        width: 5em;
    }
    textarea {
        padding: 1em;
    }
</style>
<body>
    <div>
        <div>
            <textarea id="prompt" type="text" value="" cols="80" rows="1" placeholder="One day"></textarea>
        </div>
        <select id="model">
            <option value="stories15m">stories15m</option>
            <option value="stories42m">stories42m</option>
            <option value="stories110m">stories110m</option>
        </select>

        <label>top-p</label><input id="top-p" type="number" value="1.0" step="0.1">
        <label>temperature</label><input id="temperature" type="number" value="0.9" step="0.1">
        <label>steps</label><input id="steps" type="number" value="100">
        <button id="run">run</button>
    </div>
    <textarea id="output" rows="20" cols="80"></textarea>
    <p><span>achieved tok/s: </span><span id="toks"></span></p>
    
    <script src="./run.js" type="module">
    import { load_model, load_vocab, generate } from './llama2.js';
    
    async function init() {
        await load_model('models/stories15m.bin');
        await load_vocab('tokenizer.bin');
    
        generate();
    }
    
    document.querySelector('#run').addEventListener('click', generate);
    // select another model
    document.querySelector('#model').addEventListener('change', async function () {
        await load_model(this.value + '.bin');
        generate();
    });
    
    init();
    </script>
</body>
